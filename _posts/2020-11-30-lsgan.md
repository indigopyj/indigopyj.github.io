---
layout: post
title: LSGAN과 DCGAN
date: '2020-11-30 21:00:00'
description: # Add post description (optional)
img: dcgan.png # Add image post (optional)
tags: [Papers, Generative Model]
author: # Add name author (optional)
---



오늘은 GAN의 매우매우 베이직한 모델이라고 불리는 LSGAN과 DCGAN에 대해서 설명하겠다.

​

​

​

​

# LSGAN : Least Squares GAN

​

기존 GAN모델은 실무 task에서 이미지를 사용할때 문제가 좀 있었다.

보통은 sigmoid cross entropy를 Discriminator의 로스함수로 사용하는데,

 이 함수는 바로 vanishing gradient의 문제를 가지고 있다.

예를 들면,

<img src="https://user-images.githubusercontent.com/17904547/100606793-5070cc00-334d-11eb-98b1-d099f7a3ea52.png" width=400>


이 그림을 보면 파란색 decision boundary에서, 아래부분은 fake로 간주되는 부분이고 윗부분은 real로 간주되는 부분이다.

별표모양의 데이터는 G를 업데이트하서 생성된 fake sample인데, 이들은 D에 의해서 fake로 간주되었지만 여전히 decision boundary로 부터 많이 떨어져 있다. 따라서 저런 데이터들은 제대로 학습되지 않게될 것이다.

<img src="https://user-images.githubusercontent.com/17904547/100606824-58307080-334d-11eb-9fd2-c25c9312041e.png" width=400>

이 논문에서 제안하고 있는 것은 Least squares 방법으로 바운더리로부터 멀리 떨어진 데이터에는 패널티를 주어 바운더리로 끌어오게하는것이다.

그리고 LSGAN은 학습시에 안정성을 더 줄 수 있다. vanishing gradients문제가 해결이 되니까 G도 학습시에 더 많은 gradients를 생성할 것이다.

​
![image](https://user-images.githubusercontent.com/17904547/100606838-5cf52480-334d-11eb-8fb8-9d62fe642f84.png)


LS loss는 다음과 같이 구한다. 

a는 fake label(0), b는 real label(1)을 의미한다.

그리고 c는 fake data에 대해서 G입장에서 D가 믿도록 하고 싶은 값을 말한다.(쉽게말하면 1인거같다)

​

LSGAN은 사실 핵심내용은 이게 다임.

​

그리고 추가적으로 f-divergence와의 연관성을 증명하는 수식이 나오는데

이 증명이 말하고자 하는 것은 결국 이 LSGAN이 추구하는 학습방향이 GAN과 일치함을 보여준다.

​

살짝만 언급을 해보자면

​
![image](https://user-images.githubusercontent.com/17904547/100606851-641c3280-334d-11eb-9fcb-4f563dda9caa.png)


기존 GAN에서 Jensen-Shannon divergence를 최소화하는 것이 GAN의 학습방향이었는데

이와 비슷하게 LSGAN도 그런게 있다.


아까 위의 식을 이와같이 변형할 수가 있는데 V(G)에 새로운 항이 생긴걸 볼 수 있다. 

새로 생긴 항은 어차피 G의 파라미티를 가지고 있지 않기 때문에 G의 optimization 과정에서 사용되지않는다. 따라서 있으나 없으나 상관없는데 여기서는 계산을 위해서 추가됨.

​

위 식에서 optimal D는 다음과같이 유도할 수 있음

<img src="https://user-images.githubusercontent.com/17904547/100606868-6a121380-334d-11eb-94c6-d9ff69f80128.png" width=500>

<img src="https://user-images.githubusercontent.com/17904547/100606880-6ed6c780-334d-11eb-89d5-be67a5a94b26.png" height=20>


최적의 D를 D*라고 정의한다면, V(G)는 다음과 같이 정리될 수 있다.

![image](https://user-images.githubusercontent.com/17904547/100606889-7302e500-334d-11eb-9e48-515c71c3b1dc.png)


결론적으로 LSGAN은 X^2 divergence를 최소화를 시키는 방향으로 학습이 된다.

그 말은 즉 p_d == p_g가 되도록 만드는 것을 말한다.

이는 GAN의 Jensen-Shannon divergence의 최소화와 일치하는 방향이다.

​---------------------------

# DCGAN:  Deep Convolutional GAN

​

현재 거의 모든 GAN모델은 DCGAN모델의 변형이라고 볼 수 있을정도로 엄청나게 많이 쓰이는 구조이다. 잘 알아두도록 하자.

​

DCGAN이 등장한 이유는 기존 GAN모델의 불안정성 때문이다. 때로는 무의미한 이미지를 생성하기도 하고, 이때까지만 해도 GAN이 무엇을 학습하는지 정확히 이해한 논문이 없었고 모두 추상적으로 아 이럴것이다 하고 추측단계였다고 한다. 이를 깨부신 논문이 바로 DCGAN논문이다.

​

이 논문의 contribution을 정리하면 다음과 같다.

- Convolution을 활용한 GAN구조를 제시함.

- 학습된 discriminator를 image classification tasks에 써봄.

- GAN에 의해서 학습된 필터를 visualize하였고 특정 필터가 특정 object를 그리고 있음을 캐치함.

- Generator가 백터산술연산이 가능하다는 성질을 이용하여 semantic level에서 이미지생성을 해봄.

​

DCGAN 구조의 특징은 다음과 같다.

1. pooling을 사용하지 않고 strided convolution이나 fractional-strided convolutions을 사용함.

 
![image](https://user-images.githubusercontent.com/17904547/100607231-fe7c7600-334d-11eb-8c23-e039e4ebe67f.png)


예를 들어 위의 사진은 제너레이터의 구조인데 저기서 이미지 샘플링을 위해서 피쳐맵 사이즈를 키우는 것을 볼 수 있다. 여기서 1/2 convolution(unet의 up conv생각하면 될듯)을 사용해서 맵 사이즈를 2배씩 키우고 있음.

그리고 FC layer를 모두 제거함.

정리하자면 오로지 convolution layer으로만 네트워크를 구성했다고 보면됨


2. Batch normalization을 generator와 discriminator에 추가함.

Batch norm의 장점은 아무래도 학습이 안정된다는 것 때문이다.

근데 여기서 주의할점은 배치놈을 모든 레이어에 넣어주게 되면 문제가 좀 생겨서

Generator의 output layer와 discriminator의 input layer에는 배치놈을 빼버렸음.



3. ReLU activation function 을 사용함.

generator 거의 모든 레이어는 Tanh함수를 썼지만 output layer에는 ReLU함수를 썼다.

discriminator는 모든 레이어에 leaky ReLU를 사용하였다.


사실 모델 이야기는 이게 끝이고...이 논문은 여러가지 실험을 진행하였는데 그 결과를 살펴보면 좋을것같다.

![image](https://user-images.githubusercontent.com/17904547/100607266-0d632880-334e-11eb-9b26-8e4025d6a424.png)


우선 epoch 1만 돌렸을때도 어느정도 이미지를 생성하고 있는 것으로 보아 모델이 뭔가 training example을 학습한것 같진 않다고 결론을 내렸다. 그리고 SGD + small learning rate임에도 불구하고 생성결과가 나쁘지 않으니, 모델이 데이터를 학습하는 현상은 SGD+small learning rate과는 연관이 없음이 증명되었다.


![image](https://user-images.githubusercontent.com/17904547/100607292-1b18ae00-334e-11eb-8d8f-f34e8803e42d.png)

그리고 이것은 5 epoch까지 돌린 결과임. 꽤 나쁘지않게 나왔음.


![image](https://user-images.githubusercontent.com/17904547/100607621-8ebabb00-334e-11eb-81f3-3a6b929ea4b5.png)



그리고 우리의 discriminator를 일반 supervised classification model과 성능을 비교해보게 되었다.

DCGAN은 이미지넷 데이터셋으로 학습되었고, 그 모든 레이어의 convolutioinal features를 뽑아서 4x4 짜리 grid로 풀링해준다. 그리고 나서 그 grid를 모두 이어붙혀 28672차원의 벡터로 생성한다.

그리고 L2-SVM classifier에 이를 통과시켜 분류 태스크를 진행할 수 있도록 한다.



성능을 보아하니 CNN모델보다는 못미치지만, 논문저자는 파인튜닝을 하면 좀더 나아질것이라며 미래의 학자들에게 이를 떠넘긴다(?)ㅋㅋㅋ


![image](https://user-images.githubusercontent.com/17904547/100607647-9a0de680-334e-11eb-85f6-0c83f37378e2.png)

<walking in the latent space>

그리고 walking in the latent space실험결과인데

이 말은 즉 잠재공간을 걸어다닌다.. 즉 잠재벡터 z 값을 조금씩 바꿔가면서 이미지가 어떻게 바뀌는지 보는 것이다.

왼쪽에서 오른쪽으로 갈수록 뭔가가 조금씩달라지는 것으르 볼 수 있다(예를 들면 창문이 없었는데 생긴다던지..베개?가 없었는데 생긴다던지..)


![image](https://user-images.githubusercontent.com/17904547/100607674-a42fe500-334e-11eb-8f2c-38554aade1b7.png)

그리고 discriminator가 어떤부분을 보고있는지를 visualize한 결과이다.

학습된 필터를 보면 뭔가 그 침대의 바운더리?나 창문모양 이런거에 대해서 집중적으로 보고있는 것을 알 수 있다.

저런 아웃풋을 뽑을려면 back propagation을 input까지 시키면 저런 activation map을 볼 수 있다고 한다.

​
![image](https://user-images.githubusercontent.com/17904547/100607717-ae51e380-334e-11eb-8e9f-b48a84369184.png)


그리고 이번 실험은 "Forgetting to draw certain objects"라고 해서 Generator가 객체 하나하나의 의미를 알고 이미지를 생성하고 있는지를 알아보는 ㅡ실험이다.

실험을 어떻게 했냐면, 150개의 샘플이미지 중에 window가 있는 이미지에 바운딩박스를 쳐준다.

마지막에서 두번째 conv layer에서 나온 map의 activation이 바운딩박스 영역에 있는지 없는지를 체크해본다.

그래서 바운딩박스안에 있는 부분은 +, 그렇지않은 부분은 -라고 하여 logistic regression을 한다.

이 모델을 사용하여, feature map의 weights가 0보다 큰 경우는 spatial location에서 drop해버린다.(map에서 그 부분만 지워버린다) 

그렇게 해서 생성된 샘플을 G에 넣어줬더니 다음과 같은 결과가 나온것이다. 

아래줄에 나온 결과는 창문을 지웠더니 그 부분을 어떻게든 G가 메워보려고 노력한 것 같아보인다.


![image](https://user-images.githubusercontent.com/17904547/100607750-ba3da580-334e-11eb-8bfd-6c1cfb1223fc.png)


그리고 이것이 바로  Generator가 백터산술연산이 가능하다는 성질을 이용하여 semantic level에서 이미지생성을 한 결과이다.

안경낀남자 - 안경없는 남자 + 안경없는 여자 = 안경있는 여자



참 신기하다 ㅋㅋㅋ


이로써 두 논문 정리 끝.
