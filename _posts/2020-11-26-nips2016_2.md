---
layout: post
title: NIPS 2016 &#58; Generative Adversarial Networks 논문 요약 - (2)
date: '2020-11-26 20:00:00'
description: # Add post description (optional)
img: nips2016_2.png # Add image post (optional)
tags: [Papers, Generative Model]
author: # Add name author (optional)
use_math: true
---


## Chapter 5 : Research Frontiers

​

### Non-covergence

많은 연구자들이 제일 해결할려고 하는 부분이 바로 non-convergence문제이다.

일반적인 딥러닝 모델은 로스를 최소화하는 방향으로 최적화를 진행한다. 

보통 optimization 알고리즘을 쓰면 완벽한건 아니지만 대체적으로 하향곡선을 띄게만든다.

그러나 GAN은 두 플레이어 사이의 **equilibrium** 을 찾아야되는 문제이다.

즉 어차피 한 플레이어는 하향곡선으로 움직일것이고 다른 플레이어는 상향곡선으로 움직이게 될 것인데,

가끔씩 두 플레이어가 서로의 진행을 계속 방해해서 유용한 방향으로 진행되지 못할 수도 있다.

​

따라서 이에 대한 해결책으로는 7.2와 8.2절에서 자세히 다루고 있다.

​

minimax game의 경우, 양쪽 동시에 경사하강이 수렴하는 경우는 오직 값의 갱신이 function space에서 이루어질때이다. 다만 현실에서는 값의 갱신이 parameter space에서 일어난다.

그래서 convexity properties가 적용되지 않는다.

convexity에 대한 설명은 여기 참고(<https://hwiyong.tistory.com/7>)

​

그리고 GAN은 oscillation 문제도 가지고 있는데, 이건뭐냐면 equilibrium에 도달하지 않고 샘플링을 하는 것을 말한다.(나중에 8장에서 나옴)

그리고 가장 흔한 non-convergence문제중에는 mode collapse가 있다.

​

**Mode collapse** 란 Helvetica scenario라고도 하는데

_제너레이터가 서로다른 input z에 대해서 같은 output point로 매핑되도록 학습되는 문제를 말한다._

보통은 "부분적 mode collapse"라고, 제너레이터가 같은 색이나 재질을 가진 이미지를 만들거나 혹은 같은 물체인데 다양한 관점의 이미지를 만드는 것이 많이 일어난다.

​
![image](https://user-images.githubusercontent.com/17904547/100340537-b512ea80-301e-11eb-88ba-f32f563ce19d.png)



이 그림에서 타겟 분포의 다음과 같이 작은 점들이 mode이다.  모든 mode를 포함하고 있는 분포를 띄는 방향으로 학습이 되고 있는 것이 아니라, 한번에 **오직 한 mode** 만 생성하는 방향으로 학습이 되고있다. 

따라서 discriminator가 각각의 mode를 거부하는 방향으로 학습이 될때 genereator는 서로 다른 모드들 사이를 순환한다. 쉽게말하면 D는 제대로 학습이 안되었는데 G는 학습이 잘 되었을때 이런 문제가 생긴다.

​

Mode collapse는 minimax와 maximin의 솔루션이 다르기 때문에 일어나는 문제이다.

​

이를 수식으로 살펴보면,

![image](https://user-images.githubusercontent.com/17904547/100340687-ea1f3d00-301e-11eb-9741-97417ba037b6.png)

원래 minimax는 이건데 이거를

![image](https://user-images.githubusercontent.com/17904547/100340696-ee4b5a80-301e-11eb-9c37-aba88a999134.png)

아래로 바꾸었다. 즉 G먼저 루프를 돌면서 optimization을 진행한다. 

이렇게 되면 G는 현재 고정된 D가 fake라고 생각할만한, 즉 V값이 최소가 될만한 mode를 뱉어내면 되는 것이다.

근데 이 방법이 동시에 경사하강을 보장하는 것은 아닌듯..그냥 추측성으로 채택한 방법인 것 같다..

네트워크 입장에서는 minimax나 maximin이나 구별이 되지않기 때문에 가끔씩 이렇게 순서가 바뀌어서 학습하는 경우도 있다고 한다.

​

(이부분에 대해서 잘 이해가 안가서 해당 포스팅을 참조해서 읽어보았다.

<http://jaejunyoo.blogspot.com/2017/02/unrolled-generative-adversarial-network-1.html>)

​

그리고 mode collapse가 발생하는 이유가 loss function때문은 아니고, divergence와 관련이 있는 것 같은데 Jensen-shannon이나 KL divergence가 가지고있는 문제는 아닌 것 같다. 아무튼 이 논문에서는 원인을 정확하게 모른다는 식으로 말하고 있음.

​

그래서 이것을 해결하기 위해서 학자들이 많은 시도를 하고 있는데 그 중 하나가 **minibatch features** 이다.

기본 아이디어는 다음과 같다.

Discriminator가 한 샘플을 genereated samples 및 real samples의 미니배치와 비교할 수 있도록 한다.

그 다른 샘플들간의 distance(=similarity)를 측정함으로써, discriminator는 그 한 샘플이 generated samples와 비정상적으로 비슷한지를 탐지해낼 수 있을 것이다.

_쉬운말로 다시 얘기하자면, mode collapse가 발생하면  한 이미지와 그 이미지가 속한 배치 속의 다른 이미지들간의 similarity는 비정상적으로 클 것이다._ 
discriminator가 이를 인지하고 패널티를 먹이면 mode collapse현상이 좀 해결될 것이다.

그러나 이 방법은 mode collapse는 좀 줄여주지만..외려 다른 문제를 일으키는데 물체가 여러개있는 것을 캐치하지 못하거나 perspective, global structure 등을 파악하지 못한다고 한다. 그러면서 논문에는 음..매우 끔찍한 이미지를 첨부해놓았다 꿈에 나올거같음ㅋㅋㅋㅋ아무튼 징그러운 사진을 생성해내는듯.

​

​

또 다른 해결책으로는 **unrolled GANs** 이 있다.

unrolled GAN은 **앞으로의 k step에 대해서 discriminator의 loss변화를 computational graph 계산을 통해 알아낸다음, generator의 gradient를 계산할때 이를 반영하여 back propagation해준다.**

즉 실제로는 D는 k번 update가 되지않게 된다.

그래서 maximization을 할때로 실제로는 discriminator는 학습을 수 천 step 진행해야했지만, unrolling을 통해 오직 10번 미만의 스텝정도만 하면 되었고 mode dropping 문제도 줄어들었다고 한다.

논문에서는 더이상의 설명이 없는데 나는 우선 더 찾아보고 정리를 해보았다.

​

(출처는 유재준님의 블로그)

![image](https://user-images.githubusercontent.com/17904547/100340930-3d918b00-301f-11eb-9df8-27d3166dfdb6.png)

unrolled GAN에서는 f_K라는 surrogate objective function을 도입한다.

그리고 learning rate η에 대해서 θ*_D의 local optimum을 구하는 것은 

​
![image](https://user-images.githubusercontent.com/17904547/100340945-43876c00-301f-11eb-8b8b-9b46f9eb92fe.png)


다음과 같다. k가 무한대로 가면 결국에는 최적의 discriminator를 얻을 수 있다.

![image](https://user-images.githubusercontent.com/17904547/100340965-4a15e380-301f-11eb-9e27-3970dabcec81.png)

generator와 discriminator는 다음과 같이 업데이트 될 수 있다.

여기서의 핵심은 G와 달리 D는 기존 GAN과 업데이트 방식이 같다는 것. 즉 k번 update한 gradient가 실제로 D를 업데이트는 사용되지 않는다. 그림으로 나타내면 아래와 같다.


​
![image](https://user-images.githubusercontent.com/17904547/100340978-4e420100-301f-11eb-9098-9a1665ddba16.png)


k=3이라고할때, 총 세 단계동안 forward step과 backward step이 이루어지고, 이에대한 정보를 통해 theta_G는 계속 갱신이 되지만(하늘색 화살표), theta_D는 오직 한번(붉은색 화살표)만 갱신이 된다.

​
![image](https://user-images.githubusercontent.com/17904547/100340994-5437e200-301f-11eb-87cb-073abc2ad120.png)

unrolled GAN의 결과. 마지막에는 모든 모드에 잘 맞게 생성된 것을 볼 수 있다.

​

​

​

### Discrete outputs

​

GAN 프레임워크를 설계할때 중요한 것은 **generator는 반드시 미분가능(differentiable)해야 된다는 것이다.**

이 말은 즉 generator는 _discrete data를 생성할 수 없다._ (ex. one-hot word, character representation)

그래서 아직까지 GAN을 NLP쪽에서 활용할 수 없는게 바로 이때문이다.

이 한계를 깨기위한 많은 노력이 있다.

1. 강화학습알고리즘 사용하기

2. concrete distribution or gumbel-softmax 사용하기

3. continuous value 를 샘플링하고 discrete value로 디코딩할 수 있는 제너레이터를 학습시키기

​

​

​

### Semi-supervised Learning

​

GAN은 semi-supervised learning 쪽에서도 많이 사용되고 있는데

특히 이 당시에는 _feature matching GANs_ 가 SOTA를 찍었다고 한다(2016년)

_feature matching GANs_ 의 베이직 아이디어는 다음과 같다.

바로 n개의 클래스 분류 문제를 (n+1) 클래스 분류문제로 바꾸는 것이다. 즉, 나머지 한 클래스는 fake images를 위한 클래스이다.

모든 n개의 real class의 probability는 모두 더해져서  real probability가 되고, 이렇게되면 classifier를 discriminator처럼 쓸수있다.

그리고 이 real vs fake discriminator는 unlabeled data에 대해서도 학습이 될 수 있다.

(dataset에서 온 데이터는 real 이고 generator에서 온 데이터는 fake 이런식으로..)

동시에 labeled data에 대해서도 class 를 분류하도록 학습된다.

​

### Using the code

​

GAN은 image x의 representation z를 배운다. 문제는 이 z를 활용한다는게 참 쉽지않다고 한다.

일단은 x로부터 z를 얻어내는거 자체가 힘들다.

이안 굿펠로우의 GAN 논문에서는 generator와 유사한 neural network가 p(z &#124; x)에서 샘플링하는 것이, generator가 p(x)에서 샘플링하는 것과 비슷하다는 것을 제안했지만, 구현하지는 못했다.

그래서 다른 논문들에서 인코더 네트워크를 만들어서 이를 구현했다고는 한다. 중요한 내용이 아닌거같아 넘어간다.

​

추가적으로 InfoGAN에서는 추가적인 목적함수를 사용하여 code vector의 entries를 regularize하였다. 이렇게 하면 그 code vector들이 x와의 high mutual information(= specific semantic attributes)를 가질 수 있게 한다.

​

​

​

## Chapter 7,8 : Exercise

​

### 7.1

Discriminator의 목적은 파라미터 theta_D에 대해 아래 식을 최소화시키는 것이다. 

![image](https://user-images.githubusercontent.com/17904547/100341150-89443480-301f-11eb-9530-ec9fdf766b43.png)


D의 optimal strategy는 무엇인가. 그리고 이 결과를 얻기위해서는 어떤 가정이 성립되어야 하는가?

​
![image](https://user-images.githubusercontent.com/17904547/100341167-8f3a1580-301f-11eb-9f3e-16ebbf96a981.png)

![image](https://user-images.githubusercontent.com/17904547/100341185-95c88d00-301f-11eb-8810-db3acdbf1f4d.png)


​


​

### 7.2

![image](https://user-images.githubusercontent.com/17904547/100341192-99f4aa80-301f-11eb-96f5-0dd9b2907490.png)

두 플레이어가 minimax 게임을 하려고할때 이 게임의 value function은 위와 같다.

​

문제1. 이 게임은 equilibrium(평행점)이 있나? 만약있다면 언제인가

문제2. 만약 simultaneous gradient descent 를 가지는 학습이 일어난다고 하자. 문제를 간단히 보기 위해서 연속적인 시간에 따라 기울기하강이 일어나고 있다고 할때, 무한소의 learning rate를 가질떄의 기울기하강은 아래와 같다.

![image](https://user-images.githubusercontent.com/17904547/100341212-a11bb880-301f-11eb-8db5-caec3abed3d1.png)

이때의 자취를 구하시오.

​
![image](https://user-images.githubusercontent.com/17904547/100341235-a6790300-301f-11eb-873c-ef240709403d.png)



(보충설명 필요함)

​

​

### 7.3

maximum likelihood learning의 cost를 유도하려고 한다.

우리의 목표는 J(G)를 설계하는 것인데

만약 discriminator가 optimal하다면, J(G)의 기울기는 D_KL(p_data || p_model) 과 일치한다.

이 성질을 이용하여 다음 J(G)의 함수 f를 정의하시오.

![image](https://user-images.githubusercontent.com/17904547/100341265-ae38a780-301f-11eb-8e67-10a438fcd588.png)
 

![image](https://user-images.githubusercontent.com/17904547/100341278-b1339800-301f-11eb-9da1-f78f436b8ee3.png)

![image](https://user-images.githubusercontent.com/17904547/100341293-b55fb580-301f-11eb-86bb-d20393eeb0cb.png)

​

​



​


